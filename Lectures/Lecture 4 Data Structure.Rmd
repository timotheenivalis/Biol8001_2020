---
title: "Lecture 4 Introduction to Data Structures"
author: "T. Neeman"
date: "20/07/2020"
output: html_document
---

## Data Structure

Data structure is a fundamental idea in biological data science, but it is not discussed much in the traditional data science literature. In biology, we measure responses on samples that are related or that share a common environment. Measurements from samples that share a common environment will be more correlated that measurements from samples from different environments. Here are some specific examples:

* Measurements from two leaves on a plant are more correlated than measurements from two leaves on two different plants.

* Measurements from two mice in the same litter are more correlated than measurements from two mice from different litters. 

* Measurements from two mice who share a cage are more correlated than measurements from two mice from different cages.

It's important to capture this correlation structure in our statistical model, because it can have a substantial impact on statistical inference. There are two mistakes we can make by failing to account for the structure (relatedness, common environment). Under one scenario, we might claim there is a treatment effect when the treatment effect is confounded or partially confounded with an environmental effect. Under a second scenario, we could fail a see a treatment effect because treatment differences were masked by differing environments.

Let's explore these two scenarios with a couple of examples:

## Example 1: Heights of HDR students at RSB and JCSMR

We are interested in the hypothesis that HDR students at JCSMR are taller on average than HDR students at JCSMR. Our experimental plan is to select 25 students at random from each school and measure their height. But COVID hits, and we can only find 1 student from each school, so we measure each student 25 times. Now we have our 50 measurements. Can we make the same inference as if we had measurements on 50 students?

## Example 2: Repeating experiments

We have set up a bacterial growth assay for comparing growth rates between several genetically modified organisms and the wildtype counterpart. We have run the experiment multiple times. There is considerable variation between runs. In fact the "run effect" is stronger than the genotype effect. When we combine all the measurements across the multiple experimental runs, we fail to see a difference between the mutants and the control. 

## A few comments on these examples

In *Example 1* , the only information we gain in this study is a measure of how reliable our measuring tool is. The total information about height differences comes from a sample of 2. So this study has much less information about height differences than a study with 50 *independent* measurements.

In *Example 2*, information about the genotype effect is measured within each experiment. Our analysis should ideally *combine* the information from each experiment across the set of experiments. The large variation *between* experiments is not relevant to the genotype question. Recognising that the overall measurement variation can be partitioned into between-experiment variation, and within-experiment variation, statistical inference about genotype effects should be wrt within-experiment variation. 

## Re-visiting the legume experiment

Let's return to the legume experiment from Lecture 3.2. Recall that there were 6 trays with 24 plants in each tray. The researchers arranged the treatments so that there were 4 plants with each of the 6 nitrate treatments in each tray.

First we'll import our libraries, and then have a closer look at this experiment.

```{r libraries, message = FALSE}
library(tidyverse)
library(lmerTest)
library(performance)
```

### Import and check data structure

```{r legumes}
legume <-read_csv("../Data/legume nitrate experiment.csv")
str(legume)
with(legume,table(tray, nitrate))

```

### Data exploration

We examine the association between nitrate levels and log_RMR, but we'll also include tray number in our graph. We quickly observe that there are clear tray effects- plants in the same tray are more similar RMR compared with plants in different trays.

```{r ggplot1}
ggplot(legume, aes( x=log10(nitrate), y=log_RMR, col=factor(tray)))+
  geom_point()
```

We could also look at the trend line within each tray. This way we can see more clearly that whilst there are differences in log(RMR) between trays, the effect of nitrate on log(RMR) is similar across trays.  
```{r ggplot2}
ggplot(legume, aes( x=log10(nitrate), y=log_RMR, col=factor(tray)))+
  geom_point() + 
  geom_smooth(method = "lm", alpha = 0.3)
```

### Incorporating data structure into a statistical model

Recall from an earlier lecture that a statistical model has two components. In this example, the functional component describes how nitrate levels impact log(RMR), and the random component describes variation or noise in the system. The tray is an environmental factor that contributes to the variation in log(RMR). We measure the variation around the mean behaviour as a combination of between-tray variation and within-tray variation. The effect of nitrate concentration is assessed WITHIN each tray, and these effects are averaged across trays to produce an overall estimate of nitrate concentration effect. 

We refer to tray as a *random factor*. The effect of tray on log(RMR) is called a *random effect*. 

We introduce a new function lmer() in the package lmerTest. We need this function to fit a model that allows us to add tray as a random effect. 

```{r model_fit}
model.legume2<-lmer(log_RMR ~ log10(nitrate) + (1|tray), data = legume)
anova(model.legume2)
summary(model.legume2)
```

There are a couple of things to notice in the output:
In the ANOVA table, the p-value for the nitrate concentration effect is much smaller than the p-value in the original analysis. This is because we are measuring the nitrate effect within each tray (where there is less extraneous noise). Then combine these estimates across trays; this is like adding bits of information together. 

The summary() functions makes the data structure explicit. Under Random effects, you can see how the variation is partitioned into variation *between-trays* (Intercept) and *within trays* (Residual). The between-tray variation is much larger than the within-tray variation. This confirms that tray is important data structure component, and should be part of the statistical model. 

Under Fixed effects, we see the estimates for intercept and slope. Notice that the slope estimate is the same as in the original analysis, but the standard error(SE) of the slope is much smaller. This is the same observation we made in the ANOVA table: we are estimating the nitrate effect with greater precision, so our uncertainty about our estimate is lower.

### Checking model assumptions

We have to modify our code slightly to check the model assumptions. The plot() function for an lmer object only produces the Residual vs Fitted plot:
```{r check_model}
plot(model.legume2)
```

The check_model() function in the performance package gives a more comprehensive set of model checks:

```{r check_model2}
check_model(model.legume2)
```

There is something interesting to notice here. The residuals are much smaller than in the original analysis. The residuals in the original analysis were defined as the difference: (observed data - estimated mean), whereas the residuals in this analysis are defined as the difference: (observed data - estimated mean by tray), So this model also estimates the expected values by tray, even though tray is in the random component of the model. 

The residual plot looks more scattered, and also there is a "hole" in the middle, because there were trays with overall high RMR, and trays with overall low RMR.

The bottom right normality plot assesses whether the tray effects are approximately normally distributed. 

### Summarise model using a graphic

```{r model_summary}
 newdat<-data.frame(nitrate=rep(c(0.01, .1, 1, 2, 10,100), 6), 
                   tray = rep(1:6, each = 6))

predict1<-tibble(tray = newdat$tray, nitrate = newdat$nitrate,
                  pred = predict(model.legume2, newdat))
str(predict1)

ggplot(legume, aes(x=log10(nitrate), y=log_RMR, col=factor(tray)))+
  geom_point()+
  geom_line(data=predict1, aes(x=log10(nitrate), y=pred, col=factor(tray)))+
  ylim(c(-8,-2))+
  theme_classic()
  
```

## Exercises:

(1) Ecology researchers recorded the density of thorn-like plants  (thorndensity) in multiple locations across five regions (site), and measured per hectare consumption of plant material by herbivores (herbivory). Their objective was to model the relationship between thorn density and herbivory.(thorns.csv)

    (a) Import these data, and explore how thorndensity(x) correlates on herbivory (y). Include site as a factor in your exploratory analysis.

    (b) Use geom_smooth(method = "lm") in ggplot to look at a linear fit to the data.

    (c) Use lmer() to fit the model herbivory ~ thorndensity. Include site as a random effect. 

    (d) Interpret the model output and check model assumptions using check_model in the performance package.

(2) A greenhouse experiment was designed to test the effect of soil temperature on photosynthetic rate. The experiment was conducted on 4 different tables (Position) in the greenhouse. On each table, there were 6 plants; their soils were exposed to either normal (Temp=1) or elevated (Temp=2) temperature. (photosynthesis.csv)

    (a) Import these data, and explore the effect of soil temperature on photosynthetic rate using ggplot. Include Position as a factor in your exploratory analysis.

    (b) Use lmer() to fit the model PhotoRate~Temp. Include Position as a random effect.

    (c) Interpret the model output and check model assumptions using check_model in the performance package. 

    (d) Present summary of the model in a graphic. Include p-value as evidence of a treatment effect. (hint: use emmeans() function to get mean estimates and standard errors)