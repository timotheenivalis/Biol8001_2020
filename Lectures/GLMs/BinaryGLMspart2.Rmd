---
title: "Binary GLMs part 2"
author: "Timothee Bonnet"
date: "4 September 2020"
output: 
  html_document:
    theme: united
    highlight: pygments
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


The data set "voles.csv" contains records from the survey of a wild rodent population. Among the variables is "survival", a binary variable indicating whether an individual captured on a given year survived to the next year. We want to understand variation in survival.

Today, let's consider whether sex explains variation in survival. 

```{r}
survdat <- read.csv("../../Data/voles.csv")
str(survdat)

survdat %>% group_by(sex, survival) %>%
  summarize(count=n()) %>% 
  ggplot(aes(x = sex, y=survival, size=count)) +
  geom_point()

vole_s_glm <- glm(survival ~ sex, data = survdat, family = "binomial")
summary(vole_s_glm)
```

How to interpret the summary output? What are these parameters and how do they relate to data?

```{r}
coef(vole_s_glm)

survdat %>% group_by(sex ) %>% summarize(mean=mean(survival)) 
```

Parameter estimates actually predict mean sex-specific survival, but it is not obvious because the GLM is fitted, not a the scale of probabilities, but on a transformed scale, the logit scale.

All GLMs have such a transformation. It is called the "*Link function*".

To go from a probability to the regression scale our GLM applied a logit link function:

$$
\mathrm{logit}(y) = \log(\frac{y}{1-y})
$$

To go from model predictions on the regression scale to the data scale we apply the inverse link function, which is
$$
\mathrm{logit}^{-1}(y) = \frac{1}{1+e^{-y}}
$$
in R you can run this inverse logit function with `plogis`.

So, our model told us that the predicted survival for females (the intercept) was:
```{r}
1/(1+exp(-coef(vole_s_glm)[1]))
plogis(coef(vole_s_glm)[1])
```

And the predicted survival for males was:
```{r}
plogis(coef(vole_s_glm)[1] + coef(vole_s_glm)[2] )

```

That is a rather general recipe for GLMs. When you want to calculate something on the scale of the data (that makes more sense to the human brain) from parameter estimates you:

1. Calculate the prediction using parameter estimates
2. Apply the inverse transformation used in the GLM. 

It does not work if you apply the inverse transformation on different parameters separately. 

#### Using `predict()`

```{r}
newdata_vole_sex <- tibble(sex=unique(survdat$sex))

predict(vole_s_glm, type = "link", newdata = newdata_vole_sex)
predict(vole_s_glm, type = "response", newdata = newdata_vole_sex)

```




```{r}
coef(vole_s_glm)[1] + coef(vole_s_glm)[2]*survdat$sex

predict(glm1)

data_binary$latent_y <- predict(glm1)
```

Visualise data (black) vs. what is predicted by regression coefficients:
```{r}
ggplot(data_binary, aes(x=x, y=y))+ geom_point(color="black")+
  geom_point(inherit.aes = FALSE, aes(x=x, y=latent_y), color="red")
```

The difference is because regression coefficients of a glm are expressed on a different scale.


```{r}
plogis(0)
1/(1+exp(-0))

plogis(0.98)
1/(1+exp(-0.98))

plogis(-0.98)
1/(1+exp(--0.98))
```

We can better understand what the model says after the plogis transformation:
```{r}
data_binary$transformed_latent_y <- plogis(predict(glm1))

ggplot(data_binary, aes(x=x, y=y))+ geom_point(color="black")+
  geom_point(inherit.aes = FALSE, aes(x=x, y=transformed_latent_y), color="red")
```


The model predictions obtained from the regression parameters are probabilities to observe 1 rather than a 0.

How does the model relate model predictions to the data?
The Bernouilli distribution, rbinom(n=, size= 1, prob=), a special case of the binomial distribution with size=1.

```{r}
rbinom(n = 100, size = 1, prob = 0.9)

sapply(data_binary$transformed_latent_y, 
       function(x) rbinom(n = 10, size = 1, prob = x))
```



From this example, we saw what a GLM is:

1. A linear function (reponse = intercept + slope × predictor . . . ), what you see with summary(glm1)
2. A "Link function"" = a map between the linear function (−∞ to +∞) and a
probability distribution (from 0 to 1 for Bernouilli)
3. Probability distribution (Bernouilli, Binomial, Poisson. . . ) assumed to generate
the data (either 0 or 1 for Bernouilli)

### Practice 

```{r}
survdat <- read.csv("../../Data/survivalweight.csv")

str(survdat)

```

1. Model effect of weight
```{r}
ggplot(survdat, aes(x=weight, y=survival)) +
   geom_jitter(width = 0.0, height = 0.02)  +
  geom_smooth(method = "glm", method.args = list(family="binomial"))

mw <- glm(survival ~ weight, data=survdat, family = "binomial")
summary(mw)

```

What probability of survival does the model predict for a weigth of 30?
```{r}
plogis(coef(mw)[1] + coef(mw)[2]*30)

ggplot(survdat, aes(x=weight, y=survival)) +
   geom_jitter(width = 0.0, height = 0.02)  +
  geom_smooth(method = "glm", method.args = list(family="binomial"))+
  geom_point(x=30, y=plogis(coef(mw)[1] + coef(mw)[2]*30), color="red")

```

2. Model effect of Sex
```{r}

ggplot(survdat, aes(x=sex, y=survival)) +
  geom_jitter(width = 0.1, height = 0.02) 

msex <- glm(survival ~ sex, data=survdat, family = "binomial")
summary(msex)

plogis(coef(msex)[1]) #female prediction
plogis(coef(msex)[1]+coef(msex)[2]) #male prediction

# automated calculation with predict:
newdat <- data.frame(sex=c("Female", "Male")) 
(newdat$pred <- predict(object = msex, newdata = newdat, type = "response"))

ggplot(survdat, aes(x=sex, y=survival)) +
  geom_jitter(width = 0.1, height = 0.02) +
  geom_point(data = newdat, aes(x=sex, y=pred, color=sex))

# Adding SE (approximate CI)
newdat <- data.frame(sex=c("Female", "Male")) 
predobj <- predict(object = msex, newdata = newdat,
                        type = "response", se.fit=TRUE)
newdat$pred <- predobj$fit
newdat$SE <- predobj$se.fit
newdat$lowci <- newdat$pred -1.96*newdat$SE
newdat$upci <- newdat$pred +1.96*newdat$SE

ggplot(survdat, aes(x=sex, y=survival)) +
  geom_jitter(width = 0.1, height = 0.02) +
  geom_point(data = newdat, aes(x=sex, y=pred, color=sex))+
  geom_errorbar(inherit.aes = FALSE,
                data = newdat, aes(x=sex, ymin=lowci, ymax=upci, color=sex), width=0.2)
```


3. Interaction weight:Sex?
```{r}
ggplot(survdat, aes(x=weight, y=survival, color=sex)) +
  geom_point() + geom_smooth(method = "glm", method.args = list(family="binomial"))

msw <- glm(survival ~ sex*weight, data=survdat, family = "binomial")
summary(msw)
```

4. Draw prediction and CI for low and heigh weight for case of intercation.

You must first calculate CI, then back-transform (i.e., apply plogis), or the CI goes below 0 or above 1. 
In a GLM CIs are asymetrical. 

```{r}
newdat <- expand.grid(sex=c("Female", "Male"), weight=c(18,40)) 

# this is inexact:
predobj <- predict(object = msw, newdata = newdat,
                        type = "response", se.fit=TRUE)
newdat$pred <- predobj$fit
newdat$SE <- predobj$se.fit
newdat$lowci <- newdat$pred -1.96*newdat$SE
newdat$upci <- newdat$pred +1.96*newdat$SE
newdat # some values beyond 0 / 1
```

The correct way:
```{r}
predobj <- predict(object = msw, newdata = newdat,
                        type = "link", se.fit=TRUE)
newdat$pred <- plogis(predobj$fit)
newdat$lowci <- plogis(predobj$fit -1.96*predobj$se.fit)
newdat$upci <- plogis(predobj$fit +1.96*predobj$se.fit)
newdat

ggplot(survdat, aes(x=weight, y=survival, color=sex)) +
  geom_point(alpha=0.1) + geom_smooth(method = "glm", method.args = list(family="binomial"))+
  geom_point(data=newdat, aes(x=weight, color=sex, y=pred), size=2, alpha=0.5)+
geom_errorbar(data=newdat,  inherit.aes = FALSE,
              aes(x=weight, color=sex, ymin=lowci, ymax=upci), width=1)
```



#### Interlude: What happens inside `geom_smooth()`

Let's do it "by hand" with `predict()`:

```{r}
newdata <- tibble(x=seq(min(data_linear$x), max(data_linear$x), length.out = 100))
predictions <- predict(lm0, newdata = newdata, se.fit = TRUE)
newdata$y <- predictions$fit
newdata$lowCI <- predictions$fit - 1.96*predictions$se.fit
newdata$uppCI <- predictions$fit + 1.96*predictions$se.fit


ggplot(data_linear, aes(x=x, y=y))+
  geom_point() +
  geom_line(data = newdata, color="blue") +
  geom_ribbon(data = newdata, aes(x=x, ymin=lowCI, ymax=uppCI),
              inherit.aes = FALSE, fill="blue", alpha=0.2) +
  geom_segment(aes(x=x, y=y, xend= x, yend=lm0$fitted.values))

```

#### Bonus! What happens inside `predict()`?

Let's do it "by hand" with matrix multiplication.
```{r}
newdata2 <- tibble(x=seq(min(data_linear$x), max(data_linear$x), length.out = 100),
                  y=0)

# The code below reproduces the result of predict(..., se.fit=TRUE)
mm <- model.matrix(terms(lm0),newdata2)
newdata2$y <- as.vector(mm %*% lm0$coefficients)
pvar1 <- diag(mm %*% tcrossprod(vcov(lm0),mm))
newdata2 <- tibble(
  newdata2,
  lowCI2 = newdata2$y-1.96*sqrt(pvar1),
  uppCI2 = newdata2$y+1.96*sqrt(pvar1)
) 

```
The key to compute confidence intervals is `vcov()`, which extracts the variance-covariance matrix of the uncertainty in parameters; the rest is mostly matrix multiplication.
## Assignment

1. 
2.
3.


Explain variation in annual survival in the vole data set.

```{r}
voles <- read.csv("../../Data/voles.csv")
head(voles)
```

